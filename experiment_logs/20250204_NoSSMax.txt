21:23:36.967: from collections import defaultdict
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
from dataclasses import dataclass
from functools import lru_cache
from pathlib import Path
import atexit

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import torch
torch.empty(1, device="cuda", requires_grad=True).backward() # prevents a bug on some systems
from torch import Tensor, nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.profiler import profile, record_function, ProfilerActivity
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention
# torch._inductor.config.coordinate_descent_tuning = True # turn this off for a faster compile time (but slightly slower run)
import triton
import triton.language as tl

try:
    from lovely_tensors import monkey_patch
    monkey_patch()
except ImportError:
    pass


# -----------------------------------------------------------------------------
#region  Custom operators : FP8 matmul by @YouJiacheng
@torch.library.custom_op("nanogpt::mm", mutates_args=())
def mm_op(x: Tensor, w: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor, Tensor]:
    @torch.compile
    def impl(x: Tensor, w: Tensor):
        assert x.is_contiguous() and w.is_contiguous()
        # x_f8 = x.mul(x_s).to(torch.float8_e4m3fn)
        x_f8 = x.mul(x_s).to(torch.float8_e5m2)
        # w_f8 = w.mul(w_s).to(torch.float8_e4m3fn)
        w_f8 = w.mul(w_s).to(torch.float8_e5m2)
        out = torch._scaled_mm(
            x_f8,
            w_f8.t(),
            out_dtype=torch.bfloat16,
            scale_a=x.new_tensor(1 / x_s, dtype=torch.float32),
            scale_b=x.new_tensor(1 / w_s, dtype=torch.float32),
            use_fast_accum=True,
        )
        return out, x_f8, w_f8

    return impl(x, w)

@mm_op.register_fake
def _(x: Tensor, w: Tensor, *_):
    assert x.ndim == w.ndim == 2
    assert x.shape[1] == w.shape[1]
    assert x.device == w.device
    assert x.is_contiguous() and w.is_contiguous()
    # return x @ w.t(), x.to(torch.float8_e4m3fn), w.to(torch.float8_e4m3fn)
    return x @ w.t(), x.to(torch.float8_e5m2), w.to(torch.float8_e5m2)

@torch.library.custom_op("nanogpt::mm_backward", mutates_args=())
def mm_backward_op(g: Tensor, x_f8: Tensor, w_f8: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor]:
    @torch.compile
    def impl(grad: Tensor, x_f8: Tensor, w_f8: Tensor):
        assert grad.is_contiguous()
        x_inv_s = grad.new_tensor(1 / x_s, dtype=torch.float32)
        w_inv_s = grad.new_tensor(1 / w_s, dtype=torch.float32)
        grad_inv_s = grad.new_tensor(1 / grad_s, dtype=torch.float32)
        grad_f8 = grad.mul(grad_s).to(torch.float8_e5m2)
        grad_x = torch._scaled_mm(
            grad_f8,
            w_f8.t().contiguous().t(),
            out_dtype=torch.bfloat16,
            scale_a=grad_inv_s,
            scale_b=w_inv_s,
            use_fast_accum=False,
        )
        # faster than grad_f8_t @ x_f8, for (d_out, d_in) == (50304, 768)
        grad_w = torch._scaled_mm(
            x_f8.t().contiguous(),
            grad_f8.t().contiguous().t(),
            out_dtype=torch.float32,
            scale_a=x_inv_s,
            scale_b=grad_inv_s,
            use_fast_accum=False,
        ).t()
        return grad_x, grad_w

    return impl(g, x_f8, w_f8)

@mm_backward_op.register_fake
def _(g: Tensor, x_f8: Tensor, w_f8: Tensor, *_):
    return x_f8.to(torch.bfloat16), w_f8.to(torch.float32)

def backward(ctx, grad_out: Tensor, *_):
    x_f8, w_f8 = ctx.saved_tensors
    x_s, w_s, grad_s = ctx.scales
    grad_x, grad_w = torch.ops.nanogpt.mm_backward(
        grad_out, x_f8, w_f8, x_s, w_s, grad_s
    )
    return grad_x, grad_w, None, None, None

def setup_context(ctx: torch.autograd.function.FunctionCtx, inputs, output):
    *_, x_s, w_s, grad_s = inputs
    _, x_f8, w_f8 = output
    ctx.save_for_backward(x_f8, w_f8)
    ctx.scales = x_s, w_s, grad_s
    ctx.set_materialize_grads(False)

mm_op.register_autograd(backward, setup_context=setup_context)
#endregion
# -----------------------------------------------------------------------------
#region Muon optimizer
@torch.compile
def zeropower_via_newtonschulz5(G: Tensor, steps: int) -> Tensor:
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert G.ndim >= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(-2) > G.size(-1):
        X = X.mT

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.mT
        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X

    if G.size(-2) > G.size(-1):
        X = X.mT
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven"t tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5, rank=0, world_size=1):
        self.rank = rank
        self.world_size = world_size
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        params: list[Tensor] = [*params]
        assert all(isinstance(p, Tensor) for p in params)
        sizes = {p.numel() for p in params}
        def create_update_buffer(size: int):
            b = torch.empty(self.world_size, size, dtype=torch.bfloat16, device="cuda")
            return dict(update_buffer=b, update_buffer_views=[b[i] for i in range(self.world_size)])
        param_groups = [
            dict(params=[p for p in params if p.numel() == size], **create_update_buffer(size)) for size in sizes]
        super().__init__(param_groups, defaults)

    @torch.no_grad()
    def step(self):
        for group in self.param_groups:
            lr = group["lr"]
            momentum = group["momentum"]
            nesterov = group["nesterov"]
            ns_steps = group["ns_steps"]
            update_buffer = group["update_buffer"]
            update_buffer_views: list[Tensor] = group["update_buffer_views"]
            # generate weight updates in distributed fashion
            params: list[Tensor] = group["params"]
            handle = None
            params_world = None
            def update_prev(): # optimized Muon implementation contributed by @YouJiacheng
                if params_world is None:
                    return
                assert handle is not None
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffer_views):
                    p_world.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(-2) / p_world.size(-1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                if base_i + self.rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if "momentum_buffer" not in state:
                        state["momentum_buffer"] = torch.zeros_like(g)
                    buf: Tensor = state["momentum_buffer"]
                    buf.lerp_(g, 1 - momentum)
                    g = g.lerp_(buf, momentum) if nesterov else buf
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = update_buffer_views[self.rank]
                update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather_into_tensor(update_buffer, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()
#endregion
# -----------------------------------------------------------------------------
#region PyTorch nn.Module definitions for the model

def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):
    def __init__(self, in_features: int, out_features: int, use_fp8: bool = False, x_s: float = 1.0, w_s: float = 1.0, grad_s: float = 1.0):
        super().__init__(in_features, out_features, bias=False)
        self.use_fp8 = use_fp8
        self.x_s = x_s
        self.w_s = w_s
        self.grad_s = grad_s

    def reset_parameters(self) -> None:
        std = 0.5 * (self.in_features ** -0.5) # 0.5 is a bit better than the default 1/sqrt(3)
        bound = (3 ** 0.5) * std
        with torch.no_grad():
            self.weight.uniform_(-bound, bound)

    def forward(self, x: Tensor):
        if self.use_fp8 and self.training:
            _x = x.flatten(0, -2)
            out: Tensor = torch.ops.nanogpt.mm(_x, self.weight, x_s=self.x_s, w_s=self.w_s, grad_s=self.grad_s)[0]
            return out.reshape(*x.shape[:-1], -1)
        else:
            return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):
    def __init__(self, dim: int, max_seq_len: int):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng (w/ base freq tuning)
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum("i,j -> ij", t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x_BTHD: Tensor):
        assert self.cos.size(0) >= x_BTHD.size(-3)
        cos, sin = self.cos[None, :x_BTHD.size(-3), None, :], self.sin[None, :x_BTHD.size(-3), None, :]
        x1, x2 = x_BTHD.to(dtype=torch.float32).chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x_BTHD)

class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, head_dim=128):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        hdim = num_heads * head_dim
        std = 0.5 * (dim ** -0.5)
        bound = (3 ** 0.5) * std # improved init scale by @YouJiacheng
        # merged QKV weights: suggested by many, implemented by @fernbear.bsky.social, and further improved by @YouJiacheng
        # https://x.com/hi_tysam/status/1879699187107033311
        self.qkv_w = nn.Parameter(torch.empty(3, hdim, dim).uniform_(-bound, bound))
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(head_dim, max_seq_len)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977
        # scale the attention logits by given constant, instead of the default head_dim**-0.5, by @leloykun
        # inspired by learnable scalars used by @brendanh0gan https://x.com/hi_tysam/status/1879693583898591283
        self.attn_scale = 0.12
        # Scalable-Softmax params
        # Using 1/log(512) to approximately negate the log(n), assuming 512 is the average window_size (unchecked).
        # This hasn't been tuned. Assuming that self.attn_scale was tuned, so trying to avoid deviating too much.
        # self.softmax_temps = nn.Parameter(1/torch.tensor([512] * num_heads).log())


    def forward(self, x: Tensor, ve: Tensor | None, block_mask: BlockMask, logn: Tensor):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "Must use batch size = 1 for FlexAttention"
        q, k, v = F.linear(x, self.qkv_w.flatten(end_dim=1).type_as(x)).view(B, T, 3 * self.num_heads, self.head_dim).chunk(3, dim=-2)
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        # Apply Scalable-Softmax
        # q = q * self.softmax_temps[None, None, :, None] * logn.type_as(q)[None, :, None, None]

        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask, scale=self.attn_scale)
        assert not y.isnan().any()
        y = y.transpose(1, 2)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):
    def __init__(self, dim: int):
        super().__init__()
        hdim = 4 * dim
        self.c_fc = CastedLinear(dim, hdim)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):
    def __init__(self, dim: int, num_heads: int, layer_idx: int, max_seq_len: int):
        super().__init__()
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.attn = CausalSelfAttention(dim, num_heads, max_seq_len) if layer_idx != 7 else None
        self.mlp = MLP(dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x: Tensor, ve: Tensor | None, x0: Tensor, block_mask: BlockMask, logn: Tensor):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask, logn)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size: int, embedding_dim: int, num_layers: int, num_embeddings: int = 3):
        super().__init__()
        self.num_layers = num_layers
        self.num_embeddings = num_embeddings
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, embedding_dim) for _ in range(num_embeddings)])

    def forward(self, input_seq: Tensor) -> list[Tensor | None]:
        ve = [emb(input_seq) for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = list(ve) + [None] * (self.num_layers - 2 * self.num_embeddings) + list(ve)
        return ve
#endregion
# -----------------------------------------------------------------------------
#region The main model

def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)

def create_block_masks(input_seq: Tensor, sliding_window_num_blocks: Tensor):
    BLOCK_SIZE = 128
    docs = (input_seq == 50256).cumsum(0)

    def document_causal(b, h, q_idx, kv_idx):
        causal_mask = q_idx >= kv_idx
        document_mask = docs[q_idx] == docs[kv_idx]
        return causal_mask & document_mask

    def dense_to_ordered(dense_mask: Tensor):
        num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
        indices = dense_mask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
        return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

    # manual block mask creation by @YouJiacheng
    assert len(input_seq) % BLOCK_SIZE == 0
    NUM_BLOCKS = len(input_seq) // BLOCK_SIZE
    block_idx = torch.arange(NUM_BLOCKS, dtype=torch.int32, device="cuda")
    any_causal_bm = block_idx[:, None] >= block_idx
    all_causal_bm = block_idx[:, None] > block_idx
    docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
    docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()
    any_document_bm = (docs_low[:, None] <= docs_high) & (docs_high[:, None] >= docs_low)
    all_document_bm = (docs_low[:, None] == docs_high) & (docs_high[:, None] == docs_low)
    any_bm = any_causal_bm & any_document_bm
    all_bm = all_causal_bm & all_document_bm
    partial_kv_num_blocks, partial_kv_indices = dense_to_ordered(any_bm & ~all_bm)
    full_kv_num_blocks, full_kv_indices = dense_to_ordered(all_bm)
    def build_bm(sw_num_blocks: Tensor) -> BlockMask:
        return BlockMask.from_kv_blocks(
            torch.clamp_max(partial_kv_num_blocks, torch.clamp_min(sw_num_blocks - full_kv_num_blocks, 1)),
            partial_kv_indices,
            torch.clamp_max(full_kv_num_blocks, sw_num_blocks - 1),
            full_kv_indices,
            BLOCK_SIZE=BLOCK_SIZE,
            mask_mod=document_causal,
        )

    # Scalable-Softmax needs to know the number of visible keys for each position's query
    # Gah, I give up. No SWA with SSMax.
    full_bm = build_bm(NUM_BLOCKS)
    input_pos = torch.arange(len(input_seq), device=input_seq.device)
    seq_pos = input_pos - input_pos.masked_fill((input_seq != 50256), 0).cummax(0).values
    logn = (seq_pos + 1).log()
    return full_bm, full_bm, logn, logn

    # # Does this work? Hard to test
    # right_partial = input_pos - input_pos.masked_fill((input_seq != 50256) & (input_pos % BLOCK_SIZE != 0), 0).cummax(0).values
    # long_window_size = (max(0, sliding_window_num_blocks - 1) * BLOCK_SIZE + right_partial).clamp_max(seq_pos)
    # short_window_size = (max(0, sliding_window_num_blocks // 2 - 1) * BLOCK_SIZE + right_partial).clamp_max(seq_pos)
    # long_logn = (long_window_size + 1).log()
    # short_logn = (short_window_size + 1).log()

    # breakpoint()

    # Long-short SWA block masks by @leloykun & @YouJiacheng, adapated from suggestion by @Grad62304977, following Gemma 2 paper
    # return build_bm(sliding_window_num_blocks), build_bm(sliding_window_num_blocks // 2), long_logn, short_logn

class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, model_dim: int, max_seq_len: int):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual implementation following https://arxiv.org/abs/2410.17897
        self.value_embeds = ValueEmbedding(vocab_size, model_dim, num_layers)
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, layer_idx, max_seq_len) for layer_idx in range(num_layers)])
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))
        # there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency.
        # suggested to me by @Grad62304977. this originates from Karpathy's experiments.
        # self.lm_head = CastedLinear(model_dim, next_multiple_of_n(vocab_size, n=128), use_fp8=True, x_s=2.0, w_s=2.0**9, grad_s=2.0**19)
        self.lm_head = CastedLinear(model_dim, next_multiple_of_n(vocab_size, n=128), x_s=2.0, w_s=2.0**9, grad_s=2.0**19)
        self.lm_head.weight.detach().zero_() # @Grad62304977


    def forward(self, input_seq: Tensor, target_seq: Tensor, sliding_window_num_blocks: Tensor):
        assert input_seq.ndim == 1

        long_bm, short_bm, long_ws, short_ws = create_block_masks(input_seq, sliding_window_num_blocks)

        x = x0 = norm(self.embed(input_seq)[None]) # use of norm here by @Grad62304977
        ve = self.value_embeds(input_seq)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]
        assert len(ve_enc) == self.num_encoder_layers and len(ve_dec) == self.num_decoder_layers

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        block_masks = [long_bm, short_bm, short_bm, short_bm, long_bm, short_bm]
        logns = [long_ws, short_ws, short_ws, short_ws, long_ws, short_ws]
        assert len(block_masks) == self.num_encoder_layers
        for i, block in enumerate(self.blocks[:self.num_encoder_layers]):
            x = block(x, ve_enc[i], x0, block_masks[i], logns[i])
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        block_masks.reverse()
        logns.reverse()
        assert len(block_masks) == self.num_decoder_layers
        for i, block in enumerate(self.blocks[self.num_encoder_layers:]):
            x = x + self.skip_weights[i] * skip_connections.pop()
            x = block(x, ve_dec[i], x0, block_masks[i], logns[i])

        x = norm(x)
        logits = self.lm_head(x)
        # @Grad62304977 added tanh softcapping following Gemma 2 paper, @KoszarskyB reduced it from 30 to 15, @YouJiacheng shifted it by +15 (2*sigmoid(2*x)=tanh(x)+1)
        logits = 30 * torch.sigmoid(logits.float() / 7.5)
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_seq)
        return loss

#endregion
# -----------------------------------------------------------------------------
#region MoEUT Triton kernels
# From https://github.com/RobertCsordas/moeut/blob/master/moeut/cvmm.py

@dataclass
class CVMMSel:
    raw_sel: torch.Tensor
    sel: torch.Tensor
    sel_index: torch.Tensor
    out_index: torch.Tensor | None = None
    reduction_weight: torch.Tensor | None = None

    def clone(self) -> 'CVMMSel':
        return CVMMSel(self.raw_sel, self.sel, self.sel_index, self.out_index, self.reduction_weight)


def cvmm_prepare_sel(sel: torch.Tensor, n_experts: int) -> CVMMSel:
    fsel = sel.flatten()
    ssel, sel_index = fsel.sort()
    return CVMMSel(sel, ssel.view_as(sel), sel_index, None)


def dtype_to_type_id(dtype: torch.dtype):
    if dtype == torch.float32:
        return 0
    elif dtype == torch.float16:
        return 1
    elif dtype == torch.bfloat16:
        return 2

    raise ValueError("Unknown dtype")


@triton.autotune(
    configs=[
        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),
        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),
        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),
    ],
    key=['M', 'N', 'K', 'dtype_id', 'allow_tf32']
)
@triton.jit
def cvmm_kernel(
    # Pointers to matrices
    a_ptr, b_ptr, c_ptr, index_ptr, sel_ptr, out_index_ptr,
    # Matrix dimensions
    M, N, K,
    # The stride variables represent how much to increase the ptr by when moving by 1
    # element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`
    # by to get the element one row down (A has M rows).
    stride_am, stride_ak,
    stride_bo, stride_bk, stride_bn,
    stride_cm, stride_cn,
    stride_index, stride_sel, stride_out_index,
    out_index_is_none: tl.constexpr,
    dtype_id: tl.constexpr, allow_tf32: tl.constexpr,
    # Meta-parameters
    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,
    GROUP_SIZE_M: tl.constexpr
):
    """Kernel for computing the matmul C = A x B.
    A has shape (M, K), B has shape (K, N) and C has shape (M, N)
    """
    # -----------------------------------------------------------
    # Map program ids `pid` to the block of C it should compute.
    # This is done in a grouped ordering to promote L2 data reuse.
    # See above `L2 Cache Optimizations` section for details.
    pid = tl.program_id(axis=0)

    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
    num_pid_in_group = GROUP_SIZE_M * num_pid_n
    group_id = pid // num_pid_in_group
    first_pid_m = group_id * GROUP_SIZE_M
    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)
    pid_n = (pid % num_pid_in_group) // group_size_m

    pid_m = first_pid_m + (pid % group_size_m)

    sel_first = tl.load(sel_ptr + pid_m * BLOCK_SIZE_M * stride_sel)
    sel_last = tl.load(sel_ptr + (min((pid_m + 1) * BLOCK_SIZE_M, M) - 1) * stride_sel)
    sel_all = tl.load(sel_ptr + stride_sel * ((pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M))

    for matrix_id in range(sel_first, sel_last + 1):
        # ----------------------------------------------------------
        # Create pointers for the first blocks of A and B.
        # We will advance this pointer as we move in the K direction
        # and accumulate
        # `a_ptrs` is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers
        # `b_ptrs` is a block of [BLOCK_SIZE_K, BLOCK_SIZE_N] pointers
        # See above `Pointer Arithmetics` section for details
        offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
        offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N

        remap_offs_am = tl.load(index_ptr + stride_index * offs_am)

        # Create offset pointers
        offs_k = tl.arange(0, BLOCK_SIZE_K)
        a_ptrs = a_ptr + (remap_offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)
        b_ptrs = b_ptr + matrix_id * stride_bo + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)

        # -----------------------------------------------------------
        # Iterate to compute a block of the C matrix.
        # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block
        # of fp32 values for higher accuracy.
        # `accumulator` will be converted back to fp16 after the loop.
        accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
        for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):
            # Load the next block of A and B, generate a mask by checking the K dimension.
            # If it is out of bounds, set it to 0.
            a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)
            b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)
            # We accumulate along the K dimension.

            # Triton was unhappy with passing dtypes as vars.
            if dtype_id == 1:
                a = a.to(tl.float16)
                b = b.to(tl.float16)
            elif dtype_id == 2:
                a = a.to(tl.bfloat16)
                b = b.to(tl.bfloat16)

            accumulator += tl.dot(a, b, allow_tf32=allow_tf32)

            # Advance the ptrs to the next K block.
            a_ptrs += BLOCK_SIZE_K * stride_ak
            b_ptrs += BLOCK_SIZE_K * stride_bk


        if dtype_id == 1:
            c = accumulator.to(tl.float16)
        elif dtype_id == 2:
            c = accumulator.to(tl.bfloat16)
        else:
            c = accumulator

        # -----------------------------------------------------------
        # Write back the block of the output matrix C with masks.
        offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)

        if out_index_is_none:
            remap_offs_cm = remap_offs_am
        else:
            remap_offs_cm = tl.load(out_index_ptr + stride_out_index * offs_am)

        offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)
        c_ptrs = c_ptr + stride_cm * remap_offs_cm[:, None] + stride_cn * offs_cn[None, :]
        c_mask = ((offs_cm[:, None] < M) & (sel_all[:, None] == matrix_id)) & (offs_cn[None, :] < N)
        tl.store(c_ptrs, c, mask=c_mask)


@triton.autotune(
    configs=[
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 64}, num_stages=4, num_warps=4),
        # triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 128}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 32}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 4}, num_stages=4, num_warps=4),

        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 64}, num_stages=4, num_warps=4),
        # triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 128}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 32}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 8}, num_stages=4, num_warps=4),

        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 8}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 8}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 16}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 16}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 64}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 64}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 32}, num_stages=4, num_warps=4),
        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 16, 'GROUP_SIZE_M': 8, 'K_BLOCKS': 32}, num_stages=4, num_warps=4),
    ],
    key=['M', 'N', 'K', 'out_dtype_id', 'allow_tf32', 'dtype_id'], reset_to_zero = ['c_ptr']
)
@triton.jit
def cvmm_backward_kernel3(
    # Pointers to matrices
    a_ptr, b_ptr, c_ptr, index_ptr, sel_ptr, out_index_ptr,
    # Matrix dimensions
    M, N, K,
    # The stride variables represent how much to increase the ptr by when moving by 1
    # element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`
    # by to get the element one row down (A has M rows).
    stride_am, stride_ak,
    stride_bk, stride_bn,
    stride_co, stride_cm, stride_cn,
    stride_index, stride_sel, stride_out_index,
    out_index_is_none: tl.constexpr,
    out_dtype_id: tl.constexpr, allow_tf32: tl.constexpr, dtype_id: tl.constexpr,
    # Meta-parameters
    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,
    GROUP_SIZE_M: tl.constexpr, K_BLOCKS: tl.constexpr
):
    """Kernel for computing the matmul C = A x B.
    A has shape (M, K), B has shape (K, N) and C has shape (M, N)
    """
    # -----------------------------------------------------------
    # Map program ids `pid` to the block of C it should compute.
    # This is done in a grouped ordering to promote L2 data reuse.
    # See above `L2 Cache Optimizations` section for details.
    pid = tl.program_id(axis=0)
    k_block_id = tl.program_id(axis=1)

    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
    num_pid_in_group = GROUP_SIZE_M * num_pid_n
    group_id = pid // num_pid_in_group
    first_pid_m = group_id * GROUP_SIZE_M
    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)
    pid_m = first_pid_m + (pid % group_size_m)
    pid_n = (pid % num_pid_in_group) // group_size_m

    # ----------------------------------------------------------
    # Create pointers for the first blocks of A and B.
    # We will advance this pointer as we move in the K direction
    # and accumulate
    # `a_ptrs` is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers
    # `b_ptrs` is a block of [BLOCK_SIZE_K, BLOCK_SIZE_N] pointers
    # See above `Pointer Arithmetics` section for details
    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N

    # -----------------------------------------------------------
    # Iterate to compute a block of the C matrix.
    # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block
    # of fp32 values for higher accuracy.
    # `accumulator` will be converted back to fp16 after the loop.

    a_ptrs_this = a_ptr + offs_am[:, None] * stride_am
    b_ptrs_this = b_ptr + offs_bn[None, :] * stride_bn

    # Kactual = end_i - start_i
    # Nblocks = (Kactual + BLOCK_SIZE_K - 1) // BLOCK_SIZE_K

    # WORK_PER_WORKER = (Nblocks + K_BLOCKS - 1) // K_BLOCKS
    # WORK_PER_WORKER = WORK_PER_WORKER if WORK_PER_WORKER > MIN_WORK_SIZE else MIN_WORK_SIZE


    # # Kloop_start = (Kactual + BLOCK_SIZE_K - 1) // BLOCK_SIZE_K

    # first_block_k = k_block_id * WORK_PER_WORKER
    # last_block_k = min((k_block_id+1) * WORK_PER_WORKER, Nblocks)

    block_start_index = k_block_id * BLOCK_SIZE_K * K_BLOCKS
    block_end_index = min(block_start_index + BLOCK_SIZE_K * K_BLOCKS, K) - 1

    first_mat = tl.load(sel_ptr + stride_sel * block_start_index)
    last_mat = tl.load(sel_ptr + stride_sel * block_end_index)


    for matrix_index in range(first_mat, last_mat + 1):
        accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)

        start_i = block_start_index
        end_i = block_end_index + 1
        while start_i < end_i:
            middle = (start_i + end_i) // 2
            middle_matrix = tl.load(sel_ptr + middle * stride_sel)
            if middle_matrix < matrix_index:
                start_i = middle + 1
            else:
                end_i = middle


        # # Continue binary search: find the first matrix that is > matrix_index
        start_i2 = start_i
        end_i = block_end_index + 1
        while start_i2 < end_i:
            middle = (start_i2 + end_i) // 2
            middle_matrix = tl.load(sel_ptr + middle * stride_sel)
            if middle_matrix <= matrix_index:
                start_i2 = middle + 1
            else:
                end_i = middle

        end_i = start_i2

        count = end_i - start_i

        block_mem_indices_f_base = start_i  + tl.arange(0, BLOCK_SIZE_K)

        if count > 0:
            for k in range((count + BLOCK_SIZE_K - 1) // BLOCK_SIZE_K):
                # block_mem_indices = (k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)) % K
                block_mem_indices_f = block_mem_indices_f_base + k * BLOCK_SIZE_K
                block_mem_indices = block_mem_indices_f % K
                a_index = tl.load(index_ptr + stride_index * block_mem_indices)
                if out_index_is_none:
                    b_index = a_index
                else:
                    b_index = tl.load(out_index_ptr + stride_out_index * block_mem_indices)
                sel_ok = block_mem_indices_f < end_i

                a_ptrs = a_ptrs_this + a_index[None, :] * stride_ak
                b_ptrs = b_ptrs_this + b_index[:, None] * stride_bk

                # Load the next block of A and B, generate a mask by checking the K dimension.
                # If it is out of bounds, set it to 0.
                a = tl.load(a_ptrs, mask=sel_ok[None, :], other=0.0)
                b = tl.load(b_ptrs, mask=sel_ok[:, None], other=0.0)

                if dtype_id == 1:
                    a = a.to(tl.float16)
                    b = b.to(tl.float16)
                elif dtype_id == 2:
                    a = a.to(tl.bfloat16)
                    b = b.to(tl.bfloat16)

                # We accumulate along the K dimension.
                accumulator += tl.dot(a, b, allow_tf32=allow_tf32)

            if out_dtype_id == 1:
                c = accumulator.to(tl.float16)
            elif out_dtype_id == 2:
                c = accumulator.to(tl.bfloat16)
            else:
                c = accumulator

            # -----------------------------------------------------------
            # Write back the block of the output matrix C with masks.
            offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)
            offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)
            c_ptrs = c_ptr + stride_co * matrix_index + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]
            c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
            # tl.store(c_ptrs, c, mask=c_mask)
            tl.atomic_add(c_ptrs, c, mask=c_mask)


torch.library.define("mylib::cvmm_triton", "(Tensor x, Tensor sel_index, Tensor sel, Tensor keys, ScalarType out_dtype, Tensor out_index) -> Tensor")
@torch.library.impl("mylib::cvmm_triton", "default")
def cvmm_triton(
    x: torch.Tensor,
    sel_index: torch.Tensor,
    sel: torch.Tensor,
    keys: torch.Tensor,
    out_dtype: torch.dtype,
    out_index: torch.Tensor
):
    x = x.flatten(end_dim=-2)
    assert x.shape[-1] == keys.shape[1]

    sel_shape = sel.shape
    sel = sel.flatten()

    M = sel.shape[0]
    O, K, N = keys.shape
    # Allocates output.
    out = torch.empty((M, N), device=x.device, dtype=out_dtype)
    # out = torch.zeros((M, N), device=x.device, dtype=out_dtype)
    # 1D launch kernel where each block gets its own program.

    # expected_m_per_matrix = int(math.ceil(M / O * 1.5))
    # expected_m_per_matrix = M

    grid = lambda META: (
        triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),
    )

    out_index_is_none = False
    if out_index.numel() == 1 and out_index == -1:
        out_index_is_none = True

    cvmm_kernel[grid](
        x, keys, out, sel_index, sel, out_index,
        M, N, K,
        x.stride(0), x.stride(1),
        keys.stride(0), keys.stride(1), keys.stride(2),
        out.stride(0), out.stride(1),
        sel_index.stride(0), sel.stride(0), 0 if out_index_is_none else out_index.stride(0),
        out_index_is_none=out_index_is_none,
        dtype_id = dtype_to_type_id(out.dtype), allow_tf32=False, #torch.backends.cuda.matmul.allow_tf32
    )

    return out.view(*sel_shape, N)


@torch.library.register_fake("mylib::cvmm_triton", cvmm_triton)
def cvmm_triton_abstract(x, sel_idx, sel, keys, out_dtype, out_index):
    sel_shape = sel.shape
    sel = sel.flatten()
    M = sel.shape[0]
    O, K, N = keys.shape
    out = torch.empty((M, N), device=x.device, dtype=out_dtype)
    sel_shape = sel.shape
    return out.view(*sel_shape, N)


def cvmm_triton_backward(
    x: torch.Tensor,
    sel_index: torch.Tensor,
    sel: torch.Tensor,
    grads: torch.Tensor,
    n_experts: int,
    key_dtype: torch.dtype,
    op_dtype: torch.dtype,
    out_index: torch.Tensor
):
    x = x.flatten(end_dim=-2)
    x = x.transpose(0, 1)
    grads = grads.flatten(end_dim=-2)
    sel = sel.flatten()
    M, _ = x.shape
    K, N = grads.shape
    # FIX: out must be atomic_add'able, which excludes bfloat16. Cast to key_dtype after. Maybe this could be f16
    out = torch.zeros((n_experts, M, N), device=x.device, dtype=torch.float32)
    grid = lambda META: (
        triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), triton.cdiv(K, META['BLOCK_SIZE_K'] * META['K_BLOCKS'])
    )
    out_index_is_none = False
    if out_index.numel() == 1 and out_index == -1:
        out_index_is_none = True

    cvmm_backward_kernel3[grid](
        x, grads, out, sel_index, sel, out_index,
        M, N, K,
        x.stride(0), x.stride(1),
        grads.stride(0), grads.stride(1),
        out.stride(0), out.stride(1), out.stride(2),
        sel_index.stride(0), sel.stride(0), 0 if out_index_is_none else out_index.stride(0),
        out_index_is_none=out_index_is_none,
        out_dtype_id=dtype_to_type_id(out.dtype),
        dtype_id=dtype_to_type_id(op_dtype),
        allow_tf32=False #torch.backends.cuda.matmul.allow_tf32
    )
    return out.to(dtype=key_dtype)


class CVMM(torch.autograd.Function):
    warned = False

    @staticmethod
    def forward(
        ctx,
        x: torch.Tensor,
        sel_index: torch.Tensor,
        sel: torch.Tensor,
        keys: torch.Tensor,
        out_index: torch.Tensor | None = None,
        reduction_weight: torch.Tensor | None = None
    ):
        ctx.save_for_backward(x, keys, sel, sel_index, out_index, reduction_weight)

        # out_type = get_dtype()
        out_type = x.dtype
        # out_type = torch.float32
        if out_index is None:
            out_index = torch.tensor(-1).cuda()
        res = torch.ops.mylib.cvmm_triton(x, sel_index, sel, keys, out_type, out_index)

        if reduction_weight is not None:
            res = res.view(*reduction_weight.shape, res.shape[-1])
            res = (reduction_weight.unsqueeze(-2).type_as(res) @ res).squeeze(-2)

        ctx.op_type = out_type
        ctx.keys_type = keys.dtype
        ctx.dtype = out_type
        return res.type_as(x)

    @staticmethod
    def backward(ctx, grad_output):
        x, keys, sel, sel_index, out_index, reduction_weight = ctx.saved_tensors
        keys_dt = keys

        # Backward for weight
        if reduction_weight is not None:
            # Project back the grads with he reduction weight, so the grad for the weight matrix is ok
            grad_output_w = reduction_weight.unsqueeze(-1).type_as(grad_output) @ grad_output.unsqueeze(-2)
        else:
            grad_output_w  = grad_output

        out_index_is_none = False
        if out_index is None:
            out_index_is_none = True
            out_index = torch.tensor(-1).cuda()

        grad_w = cvmm_triton_backward(
            x,
            sel_index,
            sel,
            grad_output_w,
            keys_dt.shape[0],
            ctx.keys_type,
            ctx.dtype,
            out_index=out_index
        )

        # Backward for input and reduction weight
        grad_w_off = None

        bw_index = sel_index if out_index_is_none else out_index
        bw_index_out = torch.tensor(-1).cuda()
        if reduction_weight is not None:
            # Hack the output indices to emulate repeats
            bw_index_out = bw_index
            bw_index = bw_index // reduction_weight.shape[-1]

        grad_x_full = torch.ops.mylib.cvmm_triton(
            grad_output,
            bw_index,
            sel,
            keys_dt.transpose(1,2),
            ctx.op_type,
            bw_index_out
        )

        grad_x_full = grad_x_full.view(*x.shape[:-1], -1, x.shape[-1])
        if reduction_weight is not None:
            # grad_x_full is the unscaled grad. For the input, we have to scale it, for the reduction wegiht,
            # we have to compute dot products with the input.
            grad_x = (reduction_weight.view(*grad_x_full.shape[:-1]).unsqueeze(-2).type_as(grad_x_full) @ grad_x_full).squeeze(-2)
            grad_w_off = (grad_x_full.type_as(reduction_weight) @ x.unsqueeze(-1).type_as(reduction_weight)).squeeze(-1).view_as(reduction_weight)
        elif grad_x_full.shape[-2] != 1:
            grad_x = grad_x_full.sum(-2)
        else:
            grad_x = grad_x_full

        grad_x = grad_x.view_as(x)

        return grad_x, None, None, grad_w, None, grad_w_off


def cvmm(x: torch.Tensor, sel: torch.Tensor | CVMMSel, keys: torch.Tensor):
    if not isinstance(sel, CVMMSel):
        sel = cvmm_prepare_sel(sel, keys.shape[0])
    assert x.dtype == keys.dtype, f"{x.dtype=} != {keys.dtype=}"

    return CVMM.apply(x, sel.sel_index, sel.sel, keys, sel.out_index, sel.reduction_weight)


def cvmm_prepare_sel2(sel: torch.Tensor, w: torch.Tensor | None = None) -> CVMMSel:
    # Has multiple selections for each batch element
    n_per_batch = sel.shape[-1]

    # indices = torch.arange(sel.nelement() // n_per_batch, device=sel.device, dtype=torch.int32)
    # indices = indices.repeat_interleave(n_per_batch).flatten()

    fsel = sel.flatten()
    ssel, sel_index = fsel.sort()

    # in_index = indices[sel_index]
    in_index = sel_index // n_per_batch

    return CVMMSel(sel, ssel.view_as(sel), in_index, sel_index, w)

#endregion
# -----------------------------------------------------------------------------
#region MoEUT


class SigmaMoE(torch.nn.Module):
    def __init__(self, dmodel: int, n_experts: int, expert_size: int, k: int,
                 v_dim: int | None = None):

        super().__init__()
        self.k_dim = dmodel
        self.v_dim = v_dim if v_dim is not None else dmodel
        self.n_experts = n_experts
        self.expert_size = expert_size
        self.size = self.n_experts * self.expert_size
        self.k_vec_dim = self.k_dim
        self.num_heads = k

        self.keys = torch.nn.Parameter(torch.empty(self.n_experts, self.k_vec_dim, self.expert_size))
        self.values = torch.nn.Parameter(torch.empty(self.n_experts, self.expert_size, self.v_dim))
        self.sel_expert = torch.nn.Parameter(torch.empty(self.n_experts, self.k_vec_dim))

    @torch.no_grad
    def reset_parameters(self, std_scale: float):
        # nanogpt equivalence would be std_scale=(3 ** 0.5) * 0.5
        kbound = std_scale / (self.k_dim ** 0.5)
        self.keys.uniform_(-kbound, kbound)
        self.values.zero_()
        self.sel_expert.normal_()
        self.sel_expert.div_(self.sel_expert.norm(dim=1, keepdim=True))
        self.sel_expert.mul_(std_scale / (self.k_dim) ** 0.5)

    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
        # Selection score calculation
        xnorm = norm(x)
        sel = F.linear(xnorm, self.sel_expert, None)
        sel_r = sel

        # Selection activation and topk
        sel = F.sigmoid(sel)

        sel_val, sel_index = sel.topk(self.num_heads, dim=-1, sorted=False)

        # Preprocess the selection indices. They will be needed for both layers and save some time
        sel_indices = cvmm_prepare_sel2(sel_index.int())

        # "Up-projection" layer for each head
        scores = cvmm(xnorm, sel_indices, self.keys)
        scores = F.relu(scores).square()

        # Down projection layer for each head
        sel_indices = sel_indices.clone()
        sel_indices.reduction_weight = sel_val
        sel_indices.sel_index = sel_indices.out_index
        sel_indices.out_index = None

        out = cvmm(scores, sel_indices, self.values)

        res = out.view(*x.shape[:-1], self.v_dim)
        return x + res, sel_r


class SwitchHeadRoPE(torch.nn.Module):
    def __init__(self, state_size: int, num_heads: int, n_experts: int, max_seq_len: int,
                 head_dim: int | None = None, moe_k: int = 2
                 ):

        super().__init__()

        self.input_size = state_size
        self.output_size = state_size
        self.pe_size = self.input_size
        self.moe_k = moe_k
        self.n_experts = n_experts

        self.num_heads = num_heads
        self.head_dim = head_dim or (state_size // num_heads)
        self.rotary = Rotary(self.head_dim, max_seq_len)

        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))

        self.q = torch.nn.Linear(self.input_size, self.head_dim * self.num_heads, bias=False)
        self.k = torch.nn.Linear(self.input_size, self.head_dim * self.num_heads, bias=False)

        self.v = torch.nn.Parameter(torch.empty(self.num_heads * self.n_experts, self.input_size, self.head_dim))
        self.o = torch.nn.Parameter(torch.empty(self.num_heads * self.n_experts, self.head_dim, self.output_size))
        self.sel_v = torch.nn.Parameter(torch.empty(self.num_heads * self.n_experts, self.input_size))

        self.sel_o = torch.nn.Parameter(torch.empty(self.num_heads * self.n_experts, self.input_size))

    @torch.no_grad
    def reset_parameters(self, std_scale: float):
        bound = (3 ** 0.5) * 0.5 * (self.input_size ** -0.5)
        self.q.weight.uniform_(-bound, bound)
        self.k.weight.uniform_(-bound, bound)

        self.v.normal_(0, std_scale / self.input_size ** 0.5)
        self.o.zero_()

        self.sel_v.normal_()
        self.sel_v.div_(self.sel_v.norm(dim=1, keepdim=True))
        self.sel_v.mul_(std_scale / self.input_size ** 0.5)

        self.sel_o.normal_()
        self.sel_o.div_(self.sel_o.norm(dim=1, keepdim=True))
        self.sel_o.mul_(std_scale / self.input_size ** 0.5)


    def get_sel(self, t: torch.Tensor, w: torch.Tensor) -> tuple[CVMMSel, torch.Tensor]:
        sel = F.linear(t, w)
        sel = sel_raw = sel.view(*sel.shape[:-1], self.num_heads, -1)
        sel = sel.sigmoid()

        with torch.no_grad():
            _, sel_index = sel.topk(self.moe_k, dim=-1, sorted=False)
        sel_val = torch.gather(sel, -1, sel_index)

        sel_index_shifted = (torch.arange(self.num_heads, device=sel_index.device, dtype=sel_index.dtype) * self.n_experts).unsqueeze(-1) + sel_index
        return cvmm_prepare_sel2(sel_index_shifted.flatten(-2,-1), sel_val), sel_raw


    def forward(self, x: torch.Tensor, ve: torch.Tensor | None, block_mask: BlockMask
                ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        # *src: [batch_size, out_len, c]
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "Must use batch size = 1 for FlexAttention"

        xnorm = norm(x)
        q = self.q(xnorm)
        k = self.k(xnorm)

        v_sel, v_sel_r = self.get_sel(xnorm, self.sel_v)
        o_sel, o_sel_r = self.get_sel(xnorm, self.sel_o)

        v = cvmm(x, v_sel, self.v).transpose(-2, -3)

        q = q.view(B, T, self.num_heads, self.head_dim)
        k = k.view(B, T, self.num_heads, self.head_dim)

        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q).transpose(1,2), self.rotary(k).transpose(1,2)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v

        res = flex_attention(q, k, v, block_mask=block_mask, scale=0.12)
        res = res.transpose(1, 2)

        # The output selection indices are calculated from the current state and are also used for projecting "q".
        # But that projection needs to create multiple copies for the different heads. Here we already have the
        # heads, but we have to create copies for the top-k elements. We can calculate that from the reduction
        # weight. We also want to compute not only the weighted average between the top-k elements, but also
        # of the different heads. So reshape the reduction weight accordingly.
        o_sel.sel_index = o_sel.out_index // o_sel.reduction_weight.shape[-1]
        o_sel.reduction_weight = o_sel.reduction_weight.flatten(-2)
        out = cvmm(res, o_sel, self.o)

        return x + out, o_sel_r, v_sel_r


class MoEUTLayer(torch.nn.Module):
    def __init__(self, d_model: int, num_heads: int, ff_expert_size: int, ff_n_experts: int,
                 att_n_experts: int, max_seq_len: int, head_dim: int | None = None, att_k: int = 2,
                 ff_k: int = 8):

        super().__init__()
        self.attention = SwitchHeadRoPE(
            d_model, num_heads, att_n_experts, max_seq_len=max_seq_len, head_dim=head_dim, moe_k=att_k)
        self.ffn = SigmaMoE(d_model, ff_n_experts, ff_expert_size, k=ff_k)

    def forward(self, x: torch.Tensor, ve: torch.Tensor | None, block_mask: BlockMask) -> torch.Tensor:
        x, o_sel_r, v_sel_r = self.attention(x, ve, block_mask)
        x, ffn_sel_r = self.ffn(x)
        return x, o_sel_r, v_sel_r, ffn_sel_r


class MoEUT(torch.nn.Module):
    def __init__(self, d_model: int, n_layers: int, num_heads: int, ff_expert_size: int, ff_n_experts: int,
                 att_n_experts: int, max_seq_len: int, head_dim: int | None = None, att_k: int = 2,
                 ff_k: int = 8,
                 entropy_reg: float = 0.01, att_entropy_reg: float = 0.01,
                 group_size: int = 2):
        super().__init__()

        self.entropy_reg = entropy_reg
        self.att_entropy_reg = att_entropy_reg

        self.n_repeats = n_layers // group_size
        self.layers = torch.nn.ModuleList([
            MoEUTLayer(d_model, num_heads, ff_expert_size, ff_n_experts, att_n_experts,
                       max_seq_len, head_dim, att_k, ff_k)
            for _ in range(group_size)
        ])
        self.training_step = 0

        self.embed_layer_gates = nn.Embedding(n_layers, d_model)
        self.embed_layer_biases = nn.Embedding(n_layers, d_model)
        self.lambdas = nn.Parameter(torch.tensor([[1., 0.]]).repeat(n_layers, 1))

        self.skip_weights = nn.Parameter(torch.ones(n_layers//2))

        self.reset_parameters()

    def forward(self, x: torch.Tensor, block_masks: list[BlockMask], ves: list[torch.Tensor | None]) -> tuple[torch.Tensor, torch.Tensor]:
        # Run the model
        x0 = x
        o_sels = {i: [] for i in range(len(self.layers))}
        v_sels = {i: [] for i in range(len(self.layers))}
        ffn_sels = {i: [] for i in range(len(self.layers))}

        skip_connections = []
        n_encoder_layers = self.n_repeats * len(self.layers) // 2
        for i in range(self.n_repeats * len(self.layers)):
            li = i % len(self.layers)

            gate = self.embed_layer_gates.weight[i]
            bias = self.embed_layer_biases.weight[i]
            while gate.ndim < x.ndim:
                gate = gate.unsqueeze(0)
                bias = bias.unsqueeze(0)
            x = x * (gate + 1) + bias

            if i > n_encoder_layers:
                x = x + skip_connections.pop()

            block_mask = block_masks[i % len(block_masks)]
            layer_x = x * self.lambdas[i, 0] + x0 * self.lambdas[i, 1]
            x, o_sel_r, v_sel_r, ffn_sel_r = self.layers[li](layer_x, ve=ves[i], block_mask=block_mask)

            o_sels[li].append(o_sel_r)
            v_sels[li].append(v_sel_r)
            ffn_sels[li].append(ffn_sel_r)

            if i < n_encoder_layers:
                skip_connections.append(x * self.skip_weights[i])

        def entropy_reg(sel: torch.Tensor) -> torch.Tensor:
            sel = F.log_softmax(sel, dim=-1).logsumexp(0)
            return (sel * sel.exp()).sum(-1).mean()

        ffn_reg_loss = torch.stack([
            entropy_reg(torch.stack(sel_hist, dim=1).flatten(0, 1))
            for sel_hist in ffn_sels.values()
        ]).mean()
        att_reg_loss = torch.stack([
            entropy_reg(torch.stack(sel_hist, dim=1).flatten(0, 1))
            for sel_hist in [*o_sels.values(), *v_sels.values()]
        ]).mean()

        if self.training:
            # if self.training_step % 100 == 0:
            #     for n, selsdict in zip(["o","v","f"], [o_sels, v_sels, ffn_sels]):
            #         for i, sels in selsdict.items():
            #             sels = torch.stack(sels).detach().flatten(0,2).softmax(-1)
            #             stats = sels.mean(0).cpu().float().numpy()
            #             print(f"{n}{i}: {stats}")

            #     print(f"{att_reg_loss.detach()=}")
            #     print(f"{ffn_reg_loss.detach()=}")
            # self.training_step += 1

            reg_loss = self.entropy_reg * ffn_reg_loss + self.att_entropy_reg * att_reg_loss
        else:
            reg_loss = None

        return x, reg_loss

    @torch.no_grad
    def reset_parameters(self):
        scale = (2 / (self.n_repeats * len(self.layers))) ** 0.5
        for layer in self.modules():
            if isinstance(layer, (SwitchHeadRoPE, SigmaMoE)):
                layer.reset_parameters(scale)
        self.embed_layer_gates.weight.zero_()
        self.embed_layer_biases.weight.zero_()


class MoEUTWrapper(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, model_dim: int, max_seq_len: int):
        super().__init__()
        group_size = 2
        self.embed = nn.Embedding(vocab_size, model_dim)
        self.value_embeds = ValueEmbedding(vocab_size, model_dim, num_layers, num_embeddings=group_size)
        # Select FF hparams for equal parameters & FLOPs compared to original
        ff_expert_size = 128 # ff_expert_size may be tuned without breaking comparability
        ff_k = (model_dim * 4) // ff_expert_size
        ff_n_experts = ff_k * (num_layers // group_size)
        print0(f"{ff_k=} {ff_n_experts=}")

        self.moeut = MoEUT(
            d_model=model_dim,
            n_layers=num_layers,
            num_heads=num_heads,
            ff_expert_size=ff_expert_size,
            ff_n_experts=ff_n_experts,
            att_n_experts=10, # Slightly lower params but higher FLOPs due to MoE
            max_seq_len=max_seq_len,
            head_dim=None,
            att_k=2,
            ff_k=ff_k,
            entropy_reg=0.01,
            att_entropy_reg=0.001,
            group_size=group_size,
        )
        self.lm_head = CastedLinear(model_dim, next_multiple_of_n(vocab_size, n=128), x_s=2.0, w_s=2.0**9, grad_s=2.0**19)
        self.lm_head.weight.detach().zero_() # @Grad62304977


    def forward(self, input_seq: Tensor, target_seq: Tensor, sliding_window_num_blocks: Tensor):
        assert input_seq.ndim == 1

        long_bm, short_bm = create_block_masks(input_seq, sliding_window_num_blocks)
        block_masks = [long_bm, short_bm, short_bm, short_bm, long_bm, short_bm]
        ve = self.value_embeds(input_seq)
        x = norm(self.embed(input_seq)[None]) # use of norm here by @Grad62304977
        x, reg_loss = self.moeut(x, block_masks, ve)
        x = norm(x)
        logits = self.lm_head(x)
        # @Grad62304977 added tanh softcapping following Gemma 2 paper, @KoszarskyB reduced it from 30 to 15, @YouJiacheng shifted it by +15 (2*sigmoid(2*x)=tanh(x)+1)
        logits = 30 * torch.sigmoid(logits.float() / 7.5)
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_seq)
        if self.training:
            loss = loss + reg_loss
        return loss


#endregion
# -----------------------------------------------------------------------------
#region Our own simple Distributed Data Loader

def _load_data_shard(file: Path):
    header = torch.from_file(f"{file}", False, 256, dtype=torch.int32) # header is 256 int32
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2]) # number of tokens (claimed)
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens

def distributed_data_generator(filename_pattern: str, batch_size: int, rank : int, world_size : int):
    files = sorted(Path.cwd().glob(filename_pattern))
    assert batch_size % world_size == 0
    local_batch_size = batch_size // world_size
    file_iter = iter(files) # use itertools.cycle(files) instead if you want to do multi-epoch training
    tokens, pos = _load_data_shard(next(file_iter)), 0
    while True:
        if pos + batch_size + 1 >= len(tokens):
            tokens, pos = _load_data_shard(next(file_iter)), 0
        buf = tokens[pos + rank * local_batch_size:][:local_batch_size + 1]
        inputs = buf[:-1].to(device="cuda", dtype=torch.int32, non_blocking=True) # no sync on host side;
        targets = buf[1:].to(device="cuda", dtype=torch.int64, non_blocking=True) # H2D in another stream isn"t helpful.
        pos += batch_size
        yield inputs, targets
#endregion
# -----------------------------------------------------------------------------
#region utils, hyperparams
def print0(s, console=True):
    if master_process:
        timestamp = time.strftime("%H:%M:%S.") + f"{time.time() % 1:.3f}"[2:]
        s = f"{timestamp}: {s}"
        if console:
            print(s)
        if logfile:
            with open(logfile, "a") as f:
                print(s, file=f)

def log_mem():
    print0(
        f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
        f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB",
        console=True,
    )

@dataclass(frozen=True, kw_only=True)
class Hyperparameters:
    # data
    train_files: str = "data/fineweb10B/fineweb_train_*.bin" # input .bin to train on
    val_files: str = "data/fineweb10B/fineweb_val_*.bin" # input .bin to eval validation loss on
    val_tokens: int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    num_iterations: int = 1770 # number of iterations to run
    cooldown_frac: float = 0.4 # fraction of training spent cooling down the learning rate
    # evaluation and logging
    val_loss_every: int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    seq_len: int = 48*1024 # FlexAttention sequence length
    val_seq_len: int = 4*64*1024 # FlexAttention sequence length for validation
    save_checkpoint: bool = False
    dev: bool = False

TEST_HPARAMS = Hyperparameters(
    train_files = "data/fineweb1B/fineweb_train_*.bin",
    val_files = "data/fineweb1B/fineweb_val_*.bin",
    val_tokens = 1048576,
    num_iterations = 1000, #770,
    cooldown_frac = 0.4,
    val_loss_every = 125,
    seq_len = 8*1024,
    val_seq_len = 8*1024,
    save_checkpoint = False,
    dev=False,
)
DEV_HPARAMS = Hyperparameters(
    train_files = "data/fineweb1B/fineweb_train_*.bin",
    val_files = "data/fineweb1B/fineweb_val_*.bin",
    val_tokens = 1024,
    num_iterations = 20,
    cooldown_frac = 0.4,
    val_loss_every = 125,
    seq_len = 512,
    val_seq_len = 512,
    save_checkpoint = False,
    dev=True,
)

#endregion
# -----------------------------------------------------------------------------
#region main()
master_process = None
logfile = None
if custom_logfile := len(sys.argv) > 1:
    run_id = sys.argv[1]
else:
    run_id = uuid.uuid4()
def main(args = TEST_HPARAMS):
# def main(args = DEV_HPARAMS):
    global master_process, logfile
    # torchrun sets these env variables
    rank = int(os.environ["RANK"])
    world_size = int(os.environ["WORLD_SIZE"])
    assert torch.cuda.is_available()
    device = torch.device("cuda", int(os.environ["LOCAL_RANK"]))
    torch.cuda.set_device(device)
    dist.init_process_group(backend="nccl", device_id=device)
    atexit.register(dist.destroy_process_group)
    dist.barrier()
    master_process = (rank == 0) # this process will do logging, checkpointing etc.

    # begin logging
    if master_process and not args.dev:
        os.makedirs("logs", exist_ok=True)
        logfile = f"logs/{run_id}.txt"
        print(logfile)


    # begin by printing this file (the Python code)
    print0(code, console=False)
    print0("="*100, console=False)
    # log information about the hardware/software environment this is running on
    print0(f"Running Python {sys.version}", console=False)
    print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}", console=False)
    def nvidia_smi():
        import subprocess  # avoid top level import
        return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
    print0(nvidia_smi(), console=False)
    print0("="*100, console=False)
    atexit.register(log_mem)

    torch.random.manual_seed(0)
    torch.cuda.synchronize()
    print0("Init data")
    # load data
    train_batch_size = world_size * args.seq_len
    train_loader = distributed_data_generator(args.train_files, train_batch_size, rank, world_size)

    torch.cuda.synchronize()
    print0("Init model")
    # REF: model: nn.Module = GPT(vocab_size=50257, num_layers=12, num_heads=6, model_dim=768, max_seq_len=max(args.seq_len, args.val_seq_len)).cuda()
    model: nn.Module = GPT(vocab_size=50257, num_layers=12, num_heads=3, model_dim=384, max_seq_len=max(args.seq_len, args.val_seq_len)).cuda()
    # model: nn.Module = MoEUTWrapper(vocab_size=50257, num_layers=12, num_heads=6, model_dim=768, max_seq_len=max(args.seq_len, args.val_seq_len)).cuda()
    model.bfloat16()
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()

    # count parameters
    n_params_by_dtype = defaultdict(lambda: 0)
    for name, param in model.named_parameters():
        dist.broadcast(param.detach(), 0)
        n_params_by_dtype[param.dtype] += param.numel()
    for dt, n_params in n_params_by_dtype.items():
        print0(f"{dt}: {n_params/1024/1024:.3f}Mi params")
    print0(f"total: {sum(n_params_by_dtype.values())/1024/1024:.3f}Mi params")


    torch.cuda.synchronize()
    print0("Init optimizers")
    # collect the parameters to optimize
    hidden_matrix_params = [p for n, p in model.named_parameters() if p.ndim >= 2 and "embed" not in n and "lm_head" not in n]
    embed_params = [p for n, p in model.named_parameters() if "embed" in n]
    scalar_params = [p for n, p in model.named_parameters() if p.ndim < 2]
    head_params = [model.lm_head.weight]
    params_sets = [hidden_matrix_params, embed_params, scalar_params, head_params]
    assert all(set(a).isdisjoint(b) for a in params_sets for b in params_sets if a is not b)

    assert set().union(*params_sets) == set(model.parameters())

    # init the optimizer(s)
    lr_mod = (args.seq_len/Hyperparameters().seq_len/8) ** 0.5  # Correct LR based on difference in batch size vs original w/ 8 nodes
    print(f"{lr_mod=}")
    adam_params = [dict(params=head_params, lr=0.008*lr_mod), dict(params=embed_params, lr=0.6*lr_mod), dict(params=scalar_params, lr=0.04*lr_mod)]
    # small adam epsilon by @YouJiacheng. this is an alternate method of fixing the world_size dependence
    # discovered by @fernbear.bsky.social https://x.com/hi_tysam/status/1879692937589875094
    optimizer1 = torch.optim.Adam(adam_params, betas=(0.8, 0.95), eps=1e-10, fused=True)
    optimizer2 = Muon(hidden_matrix_params, lr=0.05*lr_mod, momentum=0.95, rank=rank, world_size=world_size)
    optimizers = [optimizer1, optimizer2]

    # learning rate schedule: stable then decay
    def get_lr(step: int):
        t = 1 - step / args.num_iterations # time remaining in training
        assert 1 >= t >= 0
        w = min(t / args.cooldown_frac, 1.0) # 1 -> 0
        return w * 1.0 + (1 - w) * 0.1
    schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]
    @lru_cache(1)
    def sw_num_blks(window_size: int):
        return torch.tensor(window_size // 128, dtype=torch.int32, pin_memory=True).cuda(non_blocking=True)

    if not args.dev:
        model: nn.Module = torch.compile(model) #, dynamic=False)

    training_time_ms = 0
    # start the clock
    torch.cuda.synchronize()
    t0 = time.perf_counter()
    # begin training
    print0("Starting train loop")
    train_steps = args.num_iterations
    prof = None
    train_losses = []
    val_losses = {}

    for step in range(train_steps + 1):
        last_step = (step == train_steps)
        # if step == 5:
        #     prof = profile(record_shapes=True, profile_memory=True, with_stack=True)
        #     prof.__enter__()
        #     prof.start()
        # if prof is not None:
        #     if step == 9:
        #         prof.__exit__(None, None, None)
        #         prof.export_chrome_trace("trace.json")
        #         prof = None
        #     else:
        #         prof.step()

        # This effectively ignores timing first 10 steps, which are slower for weird reasons.
        # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
        # steps with dummy data first, and then re-initialize the model and reset the loader.
        if step == 10:
            training_time_ms = 0
            t0 = time.perf_counter()
        timed_steps = float("nan") if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

        # Linearly increase the block-wise sliding window size over training 128 -> 1792:
        # increase by @fernbear.bsky.social; block-wise by @YouJiacheng
        window_size = next_multiple_of_n(1728 * step / train_steps, n=128)

        # --------------- VALIDATION SECTION -----------------
        if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
            # stop the clock
            torch.cuda.synchronize()
            training_time_ms += 1000 * (time.perf_counter() - t0)
            model.eval()
            val_batch_size = world_size * args.val_seq_len
            assert args.val_tokens % val_batch_size == 0
            val_steps = args.val_tokens // val_batch_size
            val_loader = distributed_data_generator(args.val_files, val_batch_size, rank, world_size)
            val_loss = 0
            with torch.no_grad():
                for i in range(val_steps):
                    x, y = next(val_loader)
                    val_loss += model(x, y, sw_num_blks(window_size))
            val_loss /= val_steps
            val_losses[step] = val_loss.item()
            del val_loader
            dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
            print0(f"step:{step}/{train_steps} val_loss:{val_loss:.4f} step_avg:{training_time_ms/(timed_steps-1):.2f}ms train_time:{training_time_ms/1000:.0f}s", console=True)
            model.train()
            # start the clock again
            torch.cuda.synchronize()
            t0 = time.perf_counter()

        if last_step:
            if master_process and args.save_checkpoint:
                log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
                os.makedirs(f"logs/{run_id}", exist_ok=True)
                torch.save(log, f"logs/{run_id}/state_step{step:06d}.pt")
            # the last step only has the validation loop, so break to avoid training
            break

        # --------------- TRAINING SECTION -----------------
        inputs, targets = next(train_loader)
        step_train_losses = []
        for input_seq, target_seq in zip(inputs.split(args.seq_len), targets.split(args.seq_len)):
            loss = model(input_seq, target_seq, sw_num_blks(window_size))
            loss.backward()
            dist.all_reduce(loss, op=dist.ReduceOp.AVG)
            step_train_losses.append(loss.detach().item())
            del loss
        train_losses.append(sum(step_train_losses) / len(step_train_losses))
        train_loss = sum(train_losses[-10:]) / len(train_losses[-10:])
        for param in model.parameters():
            if param.grad is not None:
                dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
        del param
        # momentum warmup for Muon
        frac = min(step / 300, 1)
        for group in optimizer2.param_groups:
            group["momentum"] = (1 - frac) * 0.85 + frac * 0.95
        # step the optimizers and schedulers
        for opt, sched in zip(optimizers, schedulers):
            opt.step()
            sched.step()
        # null the gradients
        model.zero_grad(set_to_none=True)

        # logging
        if step < 20 or (step+1) % 50 == 0:
            approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
            print0(f"step:{step+1}/{train_steps} train_loss:{train_loss:.4f} step_avg:{approx_time/timed_steps:.2f}ms train_time:{approx_time/1000:.0f}s {torch.cuda.max_memory_allocated()=}", console=True)

    print0(f"{train_losses=}")
    print0(f"{val_losses=}")
    if master_process and logfile is not None and not custom_logfile:
        try:
            new_logfile = input("Name run? ")
        except KeyboardInterrupt:
            breakpoint()
        if new_logfile:
            old_logfile = logfile
            logfile = f"logs/{new_logfile}.txt"
            os.rename(old_logfile, logfile)
            print0(f"Renamed {old_logfile} -> {logfile}")
    else:
        print(logfile)
#endregion
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    main()

21:23:36.967: ====================================================================================================
21:23:36.967: Running Python 3.12.7 (main, Oct 16 2024, 04:37:19) [Clang 18.1.8 ]
21:23:36.967: Running PyTorch 2.7.0.dev20250110+cu126 compiled for CUDA 12.6
21:23:37.055: Tue Feb  4 21:23:36 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 3090 Ti     On  |   00000000:2D:00.0 Off |                  Off |
| 30%   45C    P2             97W /  450W |     968MiB /  24564MiB |      2%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A        26      G   /Xwayland                                   N/A      |
|    0   N/A  N/A    368501      C   /python3.12                                 N/A      |
+-----------------------------------------------------------------------------------------+

21:23:37.055: ====================================================================================================
21:23:37.056: Init data
21:23:37.056: Init model
21:23:37.968: torch.bfloat16: 111.728Mi params
21:23:37.968: total: 111.728Mi params
21:23:37.968: Init optimizers
21:23:37.985: Starting train loop
21:23:50.028: step:0/1000 val_loss:10.8258 step_avg:nanms train_time:0s
21:24:03.029: step:1/1000 train_loss:10.8259 step_avg:nanms train_time:13s torch.cuda.max_memory_allocated()=9156203008
21:24:03.263: step:2/1000 train_loss:10.8054 step_avg:nanms train_time:13s torch.cuda.max_memory_allocated()=9592097792
21:24:03.524: step:3/1000 train_loss:10.7700 step_avg:nanms train_time:13s torch.cuda.max_memory_allocated()=9598389248
21:24:03.783: step:4/1000 train_loss:10.7295 step_avg:nanms train_time:14s torch.cuda.max_memory_allocated()=9604680704
21:24:04.021: step:5/1000 train_loss:10.6702 step_avg:nanms train_time:14s torch.cuda.max_memory_allocated()=9610972160
21:24:04.216: step:6/1000 train_loss:10.6059 step_avg:nanms train_time:14s torch.cuda.max_memory_allocated()=9617263616
21:24:04.407: step:7/1000 train_loss:10.5423 step_avg:nanms train_time:14s torch.cuda.max_memory_allocated()=9623555072
21:24:04.595: step:8/1000 train_loss:10.4631 step_avg:nanms train_time:15s torch.cuda.max_memory_allocated()=9629846528
21:24:04.783: step:9/1000 train_loss:10.3638 step_avg:nanms train_time:15s torch.cuda.max_memory_allocated()=9636137984
21:24:04.974: step:10/1000 train_loss:10.2610 step_avg:nanms train_time:15s torch.cuda.max_memory_allocated()=9642429440
21:24:05.167: step:11/1000 train_loss:10.0723 step_avg:nanms train_time:0s torch.cuda.max_memory_allocated()=9648720896
21:24:05.375: step:12/1000 train_loss:9.8765 step_avg:nanms train_time:0s torch.cuda.max_memory_allocated()=9655012352
21:24:05.565: step:13/1000 train_loss:9.6607 step_avg:196.97ms train_time:1s torch.cuda.max_memory_allocated()=9661303808
21:24:05.750: step:14/1000 train_loss:9.4597 step_avg:193.80ms train_time:1s torch.cuda.max_memory_allocated()=9667595264
21:24:05.937: step:15/1000 train_loss:9.2165 step_avg:192.41ms train_time:1s torch.cuda.max_memory_allocated()=9673886720
21:24:06.130: step:16/1000 train_loss:8.9678 step_avg:192.59ms train_time:1s torch.cuda.max_memory_allocated()=9680178176
21:24:06.320: step:17/1000 train_loss:8.7172 step_avg:192.27ms train_time:1s torch.cuda.max_memory_allocated()=9686469632
21:24:06.510: step:18/1000 train_loss:8.5029 step_avg:191.88ms train_time:2s torch.cuda.max_memory_allocated()=9692761088
21:24:06.724: step:19/1000 train_loss:8.3542 step_avg:194.42ms train_time:2s torch.cuda.max_memory_allocated()=9699052544
21:24:06.917: step:20/1000 train_loss:8.2095 step_avg:194.21ms train_time:2s torch.cuda.max_memory_allocated()=9705344000
21:24:13.049: step:50/1000 train_loss:6.9118 step_avg:201.86ms train_time:8s torch.cuda.max_memory_allocated()=9894087680
21:24:23.140: step:100/1000 train_loss:6.5369 step_avg:201.84ms train_time:18s torch.cuda.max_memory_allocated()=10208660480
21:24:33.469: step:125/1000 val_loss:6.5511 step_avg:201.50ms train_time:23s
21:24:38.440: step:150/1000 train_loss:6.3691 step_avg:201.02ms train_time:28s torch.cuda.max_memory_allocated()=11328539648
21:24:48.305: step:200/1000 train_loss:6.0488 step_avg:200.04ms train_time:38s torch.cuda.max_memory_allocated()=11643112448
21:24:58.033: step:250/1000 train_loss:6.2143 step_avg:198.90ms train_time:48s torch.cuda.max_memory_allocated()=11957685248
21:25:03.250: step:250/1000 val_loss:6.1128 step_avg:199.03ms train_time:48s
21:25:13.305: step:300/1000 train_loss:5.8273 step_avg:199.39ms train_time:58s torch.cuda.max_memory_allocated()=13077564416
21:25:23.208: step:350/1000 train_loss:5.8015 step_avg:199.19ms train_time:68s torch.cuda.max_memory_allocated()=13392137216
21:25:33.370: step:375/1000 val_loss:5.8817 step_avg:199.14ms train_time:73s
21:25:38.296: step:400/1000 train_loss:5.8208 step_avg:199.00ms train_time:78s torch.cuda.max_memory_allocated()=14512016384
21:25:48.440: step:450/1000 train_loss:5.7529 step_avg:199.44ms train_time:88s torch.cuda.max_memory_allocated()=14826589184
21:25:58.548: step:500/1000 train_loss:5.7430 step_avg:199.72ms train_time:98s torch.cuda.max_memory_allocated()=15141161984
21:26:03.785: step:500/1000 val_loss:5.7384 step_avg:199.79ms train_time:98s
21:26:14.208: step:550/1000 train_loss:5.7534 step_avg:200.59ms train_time:108s torch.cuda.max_memory_allocated()=16261041152
21:26:24.080: step:600/1000 train_loss:5.5601 step_avg:200.32ms train_time:118s torch.cuda.max_memory_allocated()=16575613952
21:26:34.284: step:625/1000 val_loss:5.5870 step_avg:200.31ms train_time:123s
21:26:39.387: step:650/1000 train_loss:5.5359 step_avg:200.46ms train_time:128s torch.cuda.max_memory_allocated()=17695493120
21:26:49.420: step:700/1000 train_loss:5.5201 step_avg:200.47ms train_time:138s torch.cuda.max_memory_allocated()=18010065920
21:26:59.428: step:750/1000 train_loss:5.4854 step_avg:200.45ms train_time:148s torch.cuda.max_memory_allocated()=18324638720
21:27:04.671: step:750/1000 val_loss:5.4220 step_avg:200.50ms train_time:148s
21:27:14.885: step:800/1000 train_loss:5.3625 step_avg:200.73ms train_time:159s torch.cuda.max_memory_allocated()=19444517888
21:27:24.813: step:850/1000 train_loss:5.2538 step_avg:200.60ms train_time:169s torch.cuda.max_memory_allocated()=19759090688
21:27:34.009: step:875/1000 val_loss:5.2865 step_avg:200.57ms train_time:173s
21:27:39.999: step:900/1000 train_loss:5.2540 step_avg:200.54ms train_time:178s torch.cuda.max_memory_allocated()=20878969856
21:27:49.969: step:950/1000 train_loss:5.3177 step_avg:200.48ms train_time:188s torch.cuda.max_memory_allocated()=21193542656
21:27:59.894: step:1000/1000 train_loss:5.0522 step_avg:200.38ms train_time:198s torch.cuda.max_memory_allocated()=21508115456
21:28:05.141: step:1000/1000 val_loss:5.2160 step_avg:200.41ms train_time:198s
21:28:05.142: train_losses=[10.82585620880127, 10.784880638122559, 10.699116706848145, 10.60825252532959, 10.433051109313965, 10.283995628356934, 10.160880088806152, 9.908658981323242, 9.569876670837402, 9.335067749023438, 8.93947696685791, 8.82616901397705, 8.541277885437012, 8.598210334777832, 8.001433372497559, 7.797420501708984, 7.654302597045898, 7.765763759613037, 8.082987785339355, 7.887848377227783, 7.457513332366943, 7.45208215713501, 7.169330596923828, 6.8218913078308105, 6.584665298461914, 6.532466888427734, 7.009146213531494, 7.409095287322998, 7.302377223968506, 7.57659387588501, 7.437869071960449, 7.4477128982543945, 7.3235955238342285, 7.8270487785339355, 8.167156219482422, 7.624915599822998, 7.342525482177734, 7.082790374755859, 7.042755126953125, 7.301264762878418, 7.154139995574951, 7.11639928817749, 6.919090747833252, 7.087906360626221, 6.991975784301758, 6.623381614685059, 6.520192623138428, 7.032665729522705, 6.722336292266846, 6.949984550476074, 6.722464084625244, 6.770384311676025, 6.908079624176025, 6.78615140914917, 6.934493541717529, 7.288425922393799, 7.057275295257568, 7.111759662628174, 6.446926593780518, 7.086083889007568, 7.180233001708984, 6.5603108406066895, 6.550426959991455, 6.6503071784973145, 6.752021789550781, 6.760375499725342, 6.439776420593262, 6.473808765411377, 7.042313575744629, 6.792208671569824, 6.604180812835693, 6.5202836990356445, 7.154942989349365, 6.115714073181152, 6.230141639709473, 6.726179599761963, 6.842774868011475, 6.5108489990234375, 6.468044281005859, 6.406233310699463, 6.526942729949951, 6.390736103057861, 6.410857677459717, 6.350401878356934, 6.611260890960693, 6.433270454406738, 6.224705219268799, 6.229925632476807, 6.707156658172607, 7.5494537353515625, 6.35627555847168, 6.433353900909424, 6.35240364074707, 6.574106216430664, 6.732667446136475, 6.791926860809326, 6.494816303253174, 6.52801513671875, 6.616312503814697, 6.48866081237793, 6.254879474639893, 6.507882118225098, 6.736127853393555, 6.630175590515137, 6.484147071838379, 5.548086643218994, 6.513724327087402, 6.309366703033447, 7.036093711853027, 6.7714457511901855, 6.2515130043029785, 6.261003017425537, 6.4648518562316895, 6.5855712890625, 6.25451135635376, 6.646122455596924, 6.271420478820801, 6.175047874450684, 6.4593915939331055, 6.687919616699219, 7.021131992340088, 6.507901191711426, 6.5104451179504395, 6.7918381690979, 6.805713176727295, 6.276036262512207, 6.301706314086914, 6.733203887939453, 6.693833351135254, 6.518711090087891, 6.047043323516846, 6.472937107086182, 6.5028300285339355, 6.88794469833374, 6.211289405822754, 6.374115467071533, 5.885310649871826, 6.480216979980469, 6.118809700012207, 6.414759159088135, 6.592223167419434, 6.540919780731201, 6.536227226257324, 6.3290696144104, 6.466311454772949, 6.160926342010498, 6.61705207824707, 6.294842720031738, 6.195817470550537, 5.9573283195495605, 6.218923091888428, 6.403043746948242, 6.054087162017822, 6.409801006317139, 6.299487590789795, 5.851832389831543, 6.47784948348999, 6.234658718109131, 5.971436977386475, 6.226312160491943, 5.999484062194824, 6.161835670471191, 6.077324867248535, 6.2596845626831055, 6.265130043029785, 6.632936477661133, 6.580301761627197, 6.754573345184326, 6.369532108306885, 5.918277740478516, 6.450528621673584, 6.394863128662109, 6.261687278747559, 6.472249507904053, 6.307519912719727, 6.160066604614258, 6.22285795211792, 6.146141529083252, 6.409348964691162, 6.233654499053955, 6.420566082000732, 5.9361653327941895, 6.3963775634765625, 6.531766891479492, 7.289532661437988, 6.604990005493164, 6.170719623565674, 6.045000076293945, 6.249481201171875, 6.2534027099609375, 6.030508518218994, 5.877535343170166, 5.839303493499756, 6.256455898284912, 6.25189733505249, 6.346591472625732, 5.772721290588379, 5.705320835113525, 6.1985554695129395, 6.209281921386719, 6.3401689529418945, 5.946761131286621, 5.8303093910217285, 5.9660234451293945, 6.058091163635254, 5.988161563873291, 5.9575676918029785, 6.039177894592285, 5.863630771636963, 6.289937496185303, 6.192868709564209, 6.540976524353027, 6.053487777709961, 6.181642532348633, 6.082951068878174, 6.303934097290039, 6.198483943939209, 6.140425682067871, 5.885920524597168, 5.577782154083252, 6.060612678527832, 6.004725933074951, 6.035670280456543, 6.356378555297852, 5.945833206176758, 5.9061150550842285, 5.92197847366333, 5.977158546447754, 5.957415580749512, 5.7552032470703125, 6.296193599700928, 5.838487148284912, 6.200153350830078, 6.075756072998047, 6.104856967926025, 5.794504642486572, 6.063595771789551, 5.576282024383545, 5.713264465332031, 5.700616359710693, 6.201455593109131, 6.776123523712158, 6.410431861877441, 6.287161350250244, 6.057332515716553, 6.114549160003662, 6.1602253913879395, 5.966168403625488, 5.927411079406738, 6.241907596588135, 6.066112518310547, 6.875154495239258, 6.375354766845703, 6.2359619140625, 5.970662593841553, 6.0979437828063965, 5.643723011016846, 5.985466957092285, 6.255207538604736, 6.302762031555176, 5.926636695861816, 6.097214221954346, 6.041370868682861, 6.143271446228027, 6.016989707946777, 6.172323226928711, 6.166415214538574, 5.802987098693848, 6.101321220397949, 6.927830219268799, 6.134308815002441, 6.068231105804443, 6.04379415512085, 5.912830829620361, 6.040406703948975, 5.8510260581970215, 5.995633602142334, 6.474512100219727, 5.839212894439697, 5.588069438934326, 5.978389739990234, 6.086148738861084, 6.021205425262451, 5.878478050231934, 6.010682106018066, 6.012414932250977, 6.430435657501221, 6.425103664398193, 5.967074871063232, 5.976769924163818, 6.002437591552734, 6.25813102722168, 5.962432861328125, 5.951175689697266, 5.884697914123535, 5.4324846267700195, 5.393420219421387, 5.976566791534424, 5.751788139343262, 5.660292625427246, 5.839538097381592, 5.82919979095459, 6.021531581878662, 6.097224235534668, 5.763739585876465, 6.06372594833374, 5.881417274475098, 5.998061656951904, 5.916079044342041, 5.597354412078857, 5.812633991241455, 6.285603046417236, 6.002562999725342, 5.9574785232543945, 5.794417858123779, 6.1460161209106445, 5.90204381942749, 5.704613208770752, 5.740532875061035, 5.90294075012207, 5.6469340324401855, 5.742038249969482, 5.821743965148926, 5.943146705627441, 5.55813455581665, 6.001028060913086, 5.610212326049805, 5.677804946899414, 5.867603302001953, 5.659070014953613, 5.622593402862549, 5.712683200836182, 5.793762683868408, 6.063650131225586, 6.352680206298828, 5.7050628662109375, 5.467104911804199, 5.834450721740723, 5.884177207946777, 5.493447780609131, 5.570375919342041, 6.052606105804443, 5.936569690704346, 5.632158279418945, 5.769429683685303, 5.470729351043701, 5.842126369476318, 6.013433456420898, 6.059791564941406, 5.6673903465271, 6.034902572631836, 5.683108329772949, 5.727684497833252, 5.689575672149658, 5.6981987953186035, 6.077848434448242, 5.865484237670898, 5.593722343444824, 5.914495468139648, 5.355151176452637, 5.8295578956604, 5.792518615722656, 5.609670162200928, 5.523560523986816, 5.60640287399292, 5.847231864929199, 6.620486259460449, 5.047111511230469, 5.695132732391357, 5.598949432373047, 5.777345657348633, 5.8122239112854, 6.043644428253174, 5.677682399749756, 6.153960227966309, 5.89151668548584, 5.866135120391846, 5.846986770629883, 5.934767723083496, 5.856818199157715, 5.884213447570801, 5.896254062652588, 6.05519962310791, 6.013839244842529, 6.111661434173584, 5.5743865966796875, 5.745058059692383, 5.8207173347473145, 6.411631107330322, 6.306309223175049, 6.251656532287598, 6.008327960968018, 5.609827995300293, 5.769048690795898, 5.6137213706970215, 5.895859718322754, 5.693670749664307, 5.81001091003418, 5.678106784820557, 5.877692699432373, 5.677737712860107, 5.627721309661865, 6.083514213562012, 5.755203723907471, 5.714616298675537, 6.2551493644714355, 5.332313060760498, 5.647930145263672, 5.9857001304626465, 6.238055229187012, 6.192640781402588, 5.983030796051025, 6.241761207580566, 5.6914381980896, 6.0577311515808105, 5.796525001525879, 5.8328657150268555, 5.596739768981934, 6.164383411407471, 5.792806148529053, 5.912102222442627, 5.92999267578125, 5.898346424102783, 5.956761837005615, 5.820992946624756, 5.78764533996582, 5.474819183349609, 5.840597152709961, 5.726185321807861, 5.864437103271484, 5.796474456787109, 6.071149826049805, 5.522256851196289, 5.757999420166016, 5.708864212036133, 5.741765975952148, 5.69557523727417, 5.843623161315918, 5.631945610046387, 5.883923530578613, 6.237501621246338, 5.6665449142456055, 5.63677453994751, 6.030006408691406, 5.817263126373291, 5.730417728424072, 5.586745262145996, 5.677680015563965, 5.567470073699951, 5.578828811645508, 6.508305072784424, 6.219814777374268, 5.685766220092773, 5.643174648284912, 5.588447093963623, 5.689706802368164, 5.452515602111816, 5.855531692504883, 5.526737689971924, 5.858400821685791, 5.954549312591553, 5.808448791503906, 5.500692844390869, 5.586713790893555, 6.119136333465576, 5.640930652618408, 5.563236236572266, 5.4459967613220215, 5.880647659301758, 5.6826348304748535, 5.235044956207275, 5.815805435180664, 5.308043956756592, 5.561611175537109, 5.904154300689697, 5.313522815704346, 5.5654826164245605, 5.890307903289795, 5.683218955993652, 5.3489813804626465, 4.460676670074463, 4.8587565422058105, 5.755213260650635, 5.588494300842285, 5.697573184967041, 5.981691837310791, 5.657857894897461, 5.411991119384766, 5.64353084564209, 5.499215602874756, 5.26220178604126, 5.9337263107299805, 5.864344120025635, 5.735420227050781, 5.739479064941406, 5.4014892578125, 5.938179969787598, 6.209112644195557, 5.625573635101318, 5.720451831817627, 5.46265172958374, 5.472995758056641, 5.798017978668213, 5.688673496246338, 5.45232629776001, 5.310096740722656, 5.377833366394043, 5.210041046142578, 5.266138076782227, 5.657465934753418, 5.728916645050049, 5.618829727172852, 5.8802032470703125, 5.853724956512451, 5.843693256378174, 5.357972621917725, 5.46998405456543, 5.923508644104004, 5.822639465332031, 5.636645317077637, 5.8699846267700195, 5.924596786499023, 5.5340681076049805, 5.562525749206543, 5.545796871185303, 5.785431861877441, 5.675154209136963, 5.552527904510498, 5.76265287399292, 5.7855753898620605, 5.525468826293945, 5.566215991973877, 5.860918045043945, 5.6324143409729, 5.544547080993652, 5.822535514831543, 5.7309184074401855, 5.7205352783203125, 5.710607528686523, 5.865373134613037, 5.691550254821777, 5.667882442474365, 5.626877784729004, 6.248661994934082, 5.743151664733887, 5.774166107177734, 5.598812103271484, 5.783986568450928, 5.791096210479736, 5.607646465301514, 6.119136810302734, 5.792375087738037, 5.43215799331665, 5.64210844039917, 5.387484550476074, 5.59263801574707, 5.829315185546875, 5.412961483001709, 5.743521690368652, 5.623234272003174, 5.448331356048584, 5.4762420654296875, 5.581033706665039, 5.479572772979736, 5.725142955780029, 5.104674816131592, 5.857696533203125, 5.397021770477295, 5.659684181213379, 6.035642623901367, 6.957273006439209, 6.44182825088501, 5.811537265777588, 6.527751922607422, 5.6852946281433105, 6.045743465423584, 5.595645904541016, 6.180083751678467, 5.387423038482666, 5.826473236083984, 5.18483304977417, 5.197727680206299, 6.123535633087158, 5.681792259216309, 5.480926036834717, 5.197944641113281, 5.282120704650879, 5.335872173309326, 5.329161167144775, 5.783994197845459, 5.429824352264404, 5.7443389892578125, 5.59422492980957, 5.388211727142334, 5.451602458953857, 5.21900749206543, 5.602324485778809, 5.888354301452637, 5.79681396484375, 5.486073017120361, 5.338736534118652, 5.577449798583984, 5.147911548614502, 5.225699424743652, 5.0424723625183105, 5.740099906921387, 5.532864570617676, 5.7218098640441895, 5.698655605316162, 5.2176361083984375, 5.646098613739014, 5.820671081542969, 5.467617988586426, 5.550071716308594, 5.8955841064453125, 5.410299777984619, 5.602077484130859, 5.172149658203125, 5.608249664306641, 5.48783016204834, 5.459619045257568, 5.379082679748535, 5.472103118896484, 5.543217658996582, 5.220133304595947, 5.454187393188477, 5.702929496765137, 5.331587791442871, 5.62471866607666, 5.847808837890625, 5.991874694824219, 5.255354881286621, 5.487880706787109, 5.456086158752441, 5.455507278442383, 5.432025909423828, 5.573536396026611, 5.627808570861816, 5.676564693450928, 5.1532301902771, 4.932291507720947, 5.783761501312256, 5.5746989250183105, 5.511887550354004, 5.909515380859375, 5.48084831237793, 5.532444953918457, 5.683757781982422, 5.522521018981934, 5.426867961883545, 5.350688457489014, 5.675119876861572, 5.660462379455566, 5.402206897735596, 5.493730068206787, 5.528008460998535, 5.541231632232666, 5.541446208953857, 5.245390892028809, 5.502082347869873, 5.3850579261779785, 5.379899024963379, 6.259732723236084, 5.352331161499023, 5.345299243927002, 5.326650142669678, 5.197346210479736, 5.352702617645264, 5.570687294006348, 5.632538318634033, 5.187389850616455, 5.452077388763428, 5.3515543937683105, 5.755867004394531, 5.583161354064941, 5.413547515869141, 5.749621391296387, 5.434221267700195, 5.596904754638672, 5.337409496307373, 5.197855472564697, 5.365169048309326, 5.366824150085449, 5.655354022979736, 5.4012885093688965, 5.370368003845215, 5.634119987487793, 5.555529594421387, 5.664383888244629, 5.315756320953369, 5.400741100311279, 5.1136274337768555, 5.358474254608154, 5.514354228973389, 5.011837482452393, 5.693999767303467, 6.546088218688965, 5.807610988616943, 5.32995080947876, 5.424281597137451, 5.858110427856445, 5.224518775939941, 5.305454254150391, 5.378959655761719, 5.60979700088501, 5.266728401184082, 5.492379188537598, 5.605235576629639, 5.340731620788574, 5.430075168609619, 5.467369079589844, 5.330249309539795, 5.670617580413818, 5.250387668609619, 5.120678901672363, 5.179328441619873, 6.1401286125183105, 5.102564334869385, 5.380916595458984, 5.520923614501953, 5.312553882598877, 5.693455696105957, 5.495753288269043, 5.446261405944824, 5.221201419830322, 5.590335369110107, 5.025663375854492, 5.241212844848633, 5.274495601654053, 5.3276567459106445, 5.358400344848633, 5.388225555419922, 5.176599025726318, 5.1147356033325195, 5.721325874328613, 5.594949245452881, 5.4847517013549805, 5.246832847595215, 5.192206859588623, 5.385148525238037, 5.538678169250488, 5.458532810211182, 5.349404335021973, 5.08408784866333, 5.150086402893066, 5.852451801300049, 5.300344467163086, 5.660562038421631, 5.2659783363342285, 6.194084644317627, 6.163964748382568, 5.315141201019287, 5.316372394561768, 5.470322608947754, 5.577709197998047, 5.5436906814575195, 5.602849960327148, 5.357113838195801, 5.305474281311035, 5.224038124084473, 4.856466770172119, 5.522197246551514, 5.379634857177734, 5.638899803161621, 5.641138553619385, 5.410638332366943, 5.5767107009887695, 5.050415992736816, 5.176219463348389, 5.358113765716553, 5.235374927520752, 5.245580196380615, 5.396110534667969, 5.3918137550354, 5.642062187194824, 5.035007476806641, 5.382540702819824, 5.207657337188721, 5.486347198486328, 5.470954418182373, 5.371093273162842, 5.35019063949585, 5.411584854125977, 5.342069149017334, 5.499927043914795, 5.523847579956055, 5.720512866973877, 5.354006290435791, 5.230896949768066, 5.760144233703613, 5.400055885314941, 5.339400291442871, 5.56898832321167, 5.094119548797607, 5.057694435119629, 5.426046848297119, 5.576223850250244, 5.622402191162109, 5.3800129890441895, 5.159638404846191, 5.259848594665527, 5.294435977935791, 5.447082042694092, 5.3163743019104, 5.201644420623779, 5.682925701141357, 5.30374002456665, 5.240541458129883, 4.9575419425964355, 5.437930107116699, 5.250920295715332, 5.0360918045043945, 5.412868022918701, 5.42070198059082, 5.243422508239746, 5.037746906280518, 5.453711032867432, 5.725330352783203, 5.503579616546631, 5.227841377258301, 5.367457866668701, 5.239990711212158, 5.343414783477783, 5.725227355957031, 5.701555252075195, 5.105756759643555, 5.153303146362305, 5.0577921867370605, 5.451227188110352, 5.011502742767334, 5.103819370269775, 5.412071704864502, 5.089290618896484, 5.313266754150391, 5.316229343414307, 5.256297588348389, 5.168364524841309, 5.567216873168945, 5.0998663902282715, 5.451380729675293, 5.337499618530273, 5.4227728843688965, 5.603036880493164, 5.174278259277344, 5.276946067810059, 5.255045413970947, 5.106034755706787, 5.444663047790527, 4.963178634643555, 4.9545817375183105, 5.086614608764648, 5.097458839416504, 5.1925506591796875, 5.12608003616333, 5.208543300628662, 5.133159637451172, 5.4241414070129395, 5.582951545715332, 5.904098033905029, 5.7473039627075195, 5.2823591232299805, 5.316609859466553, 5.732346057891846, 4.626649856567383, 5.05652379989624, 5.645286560058594, 5.442716598510742, 5.49770450592041, 5.14302396774292, 5.141850471496582, 5.168240070343018, 4.995752811431885, 5.162757396697998, 5.010668754577637, 5.13720178604126, 5.138389587402344, 4.7667927742004395, 5.036394119262695, 5.19541597366333, 4.789666175842285, 5.252979278564453, 5.166533946990967, 4.919633388519287, 5.39257287979126, 5.278878211975098, 5.321658134460449, 5.288395404815674, 4.9233856201171875, 5.391308307647705, 5.253705978393555, 5.25728702545166, 5.255775451660156, 5.156134128570557, 5.439326763153076, 5.277185440063477, 5.336780548095703, 4.753150463104248, 5.466734886169434, 5.393401145935059, 5.204596519470215, 5.044628143310547, 5.309546947479248, 5.1031999588012695, 5.492133140563965, 5.056103229522705, 5.115577220916748, 5.258865833282471, 5.133263111114502, 5.505672454833984, 5.027466297149658, 5.308351039886475, 5.470658302307129, 5.118680953979492, 5.309892654418945, 5.254753112792969, 5.127696990966797, 5.21258020401001, 5.107519149780273, 5.143599033355713, 5.438857078552246, 5.139036178588867, 5.0713677406311035, 4.955831527709961, 5.2784810066223145, 5.513933181762695, 5.158873081207275, 5.318498134613037, 5.484732627868652, 5.320300579071045, 5.260929107666016, 5.338518142700195, 5.4587249755859375, 5.296795845031738, 5.104373931884766, 5.168590545654297, 5.082322597503662, 5.224680423736572, 5.361209392547607, 5.147695541381836, 4.949137210845947, 5.21597146987915, 5.080301284790039, 5.344295024871826, 5.353678226470947, 5.278903961181641, 5.042954444885254, 5.45310115814209, 5.401562213897705, 5.403812408447266, 5.602488994598389, 5.368570804595947, 5.353823661804199, 4.9478983879089355, 5.170498847961426, 5.313385486602783, 5.11290168762207, 5.720645427703857, 5.442633628845215, 4.902096748352051, 5.152245044708252, 5.6592206954956055, 5.145515441894531, 5.126444339752197, 4.931426048278809, 5.134573936462402, 5.06829309463501, 5.130210876464844, 5.401913642883301, 5.393517971038818, 5.290396690368652, 5.211349010467529, 5.1245527267456055, 5.020881652832031, 5.413405895233154, 4.9555888175964355, 5.279972076416016, 5.02727746963501, 5.137666702270508, 5.131351470947266, 5.538561820983887, 4.9565887451171875, 5.059027671813965, 4.822535037994385, 5.323064804077148, 4.998430252075195, 4.8560614585876465, 5.148460865020752, 6.070291519165039, 4.850254058837891, 4.7566094398498535, 5.091878414154053, 4.8994832038879395, 5.12501859664917, 4.876858234405518, 4.897523403167725, 5.22694730758667, 5.069927215576172, 5.467726707458496, 5.022176265716553, 4.844925880432129]
21:28:05.143: val_losses={0: 10.825848579406738, 125: 6.551115036010742, 250: 6.112812042236328, 375: 5.881729602813721, 500: 5.738409042358398, 625: 5.5869879722595215, 750: 5.422008514404297, 875: 5.286458969116211, 1000: 5.215960502624512}
21:28:21.167: Renamed logs/19ca9073-9f55-4d25-a809-b526f0793e6c.txt -> logs/20250204_NoSSMax.txt
21:28:21.169: peak memory allocated: 20511 MiB reserved: 21476 MiB
